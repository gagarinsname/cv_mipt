{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "DATA_PATH = r'D:\\code\\hw\\miptcv\\code\\hw#5\\Train'\n",
    "classes = map(int, os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Загрузка данных\n",
    "def collect_data(data_path, augment=True):\n",
    "    data = [[] for i in classes]\n",
    "    for cl in classes:\n",
    "        for filename in tqdm(glob(os.path.join(data_path, str(cl), '*')), desc='Read {}'.format(cl)):\n",
    "            data[cl].append(cv2.imread(filename, 0))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_rate(src):\n",
    "    return float((src > 0).sum()) / src.size\n",
    "\n",
    "def gradient_x(src):\n",
    "    return float((src[:, 1:] - src[:, :-1]).sum()) / (src[1:, :].size)\n",
    "\n",
    "def gradient_y(src):\n",
    "    return float((src[1:, :] - src[:-1, :]).sum()) / (src[1:, :].size)\n",
    "\n",
    "def vertical_projection(src):\n",
    "    return float(sum(src.sum(axis=1) < 10)) / (1 + src.shape[0])\n",
    "\n",
    "def horizontal_projection(src):\n",
    "    return float(sum(src.sum(axis=0) < 10)) / (1 + src.shape[1])\n",
    "\n",
    "def get_fv(src):\n",
    "    return np.array([white_rate(src),\n",
    "                      gradient_x(src),\n",
    "                      gradient_y(src),\n",
    "                      vertical_projection(src)+horizontal_projection(src)\n",
    "                    ])\n",
    "    \n",
    "def extract_features(src, size=None, aug_codes=[]):\n",
    "    process_dict = {1: np.fliplr, 2: np.rot90, 3: np.flipud}\n",
    "    features = list()\n",
    "    features.append(get_fv(src))\n",
    "    for code in aug_codes:\n",
    "        dst = process_dict[code](src)\n",
    "        features.append(get_fv(dst))\n",
    "    return np.vstack(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использованные признаки:\n",
    "\n",
    "1) Доля белых пикселей на изображении, поскольку эта величина по моим наблюдениям различается для различных классов и близка для изображений одного класса\n",
    "\n",
    "2) Сумма горизонтальных и вертикальных градиентов, что должно помочь отличить привычные штрих-коды от QR-кодов и сканов\n",
    "\n",
    "3) Отношение длин белых участков на горизонтальных и вертикальных проекциях изображения, что может позволить различать классы 1,2 или 0,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем SVM\n",
    "\n",
    "SVM считается хорошей моделью для классификации изображений. Используем стандартное ядро RBF для учёта нелинейности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dcb1d184924bc29b62a410d50b7cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ebe8157cf4f119d4689d201fcee33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5294aad41a4e9594cc08b1a395f2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc31074a7d3494f951a114d5e2e6f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7171d7aeec7140908dd1dd79291a49cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789ba53add7f4b24800d4330c7e6e48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = collect_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_codes = []\n",
    "X = np.vstack([np.vstack([extract_features(src, aug_codes=aug_codes) for src in raw_data[l]]) for l in labels])\n",
    "y = np.concatenate([[l] * (1+len(aug_codes))*len(raw_data[l]) for l in labels])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.8, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=2, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf0 = SVC(random_state=2)\n",
    "clf0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 0.999642857143\n",
      "Val set: 1.0\n",
      "Full set: 0.999714285714\n"
     ]
    }
   ],
   "source": [
    "print'Train set: {}'.format( clf0.score(X_train, y_train))\n",
    "print 'Val set: {}'.format( clf0.score(X_val, y_val))\n",
    "print 'Full set: {}'.format( clf0.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем искусственно расширить доступную нам выборку\n",
    "В изображениях тестовой выборки присутствуют изображения, похожие на изображения из обучающей выборки, но повёрнутые на кратные 90 градусам углы. Пополним обучающую выборку подобными изображениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_codes = [1,2,3]\n",
    "aX = np.concatenate([np.vstack([extract_features(src, aug_codes=aug_codes) for src in raw_data[l]]) for l in labels])\n",
    "ay = np.concatenate([[l] * (1+len(aug_codes))*len(raw_data[l]) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "aX_train, aX_val, ay_train, ay_val = train_test_split(aX, ay, train_size = 0.8, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=2, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_a = SVC(random_state=2)\n",
    "clf_a.fit(aX, ay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 0.999821428571\n",
      "Val set: 1.0\n",
      "Full set: 0.999857142857\n"
     ]
    }
   ],
   "source": [
    "print 'Train set: {}'.format( clf_a.score(X_train, y_train))\n",
    "print 'Val set: {}'.format( clf_a.score(X_val, y_val))\n",
    "print 'Full set: {}'.format( clf_a.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим на всей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=2, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_res = SVC(random_state=2)\n",
    "clf_res.fit(aX, ay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full set: 0.999857142857\n"
     ]
    }
   ],
   "source": [
    "print 'Full set: {}'.format( clf_a.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_output(model, data_path, output_path):\n",
    "    raw_data = list()\n",
    "    file_list = glob(os.path.join(data_path, '*'))\n",
    "    for filename in tqdm(file_list):\n",
    "            raw_data.append(cv2.imread(filename, 0))\n",
    "    features = np.vstack([extract_features(src) for src in raw_data])\n",
    "    answers = model.predict(features)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('# fname,class\\n')\n",
    "        for i in range(len(file_list)):\n",
    "            f.write('{},{}\\n'.format(os.path.basename(file_list[i]),answers[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59bbbfd320c422387bf0ceb7efb0394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_PATH = 'Test'\n",
    "CSV_PATH = r'res.csv'\n",
    "\n",
    "generate_csv_output(clf_res, 'test', CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
